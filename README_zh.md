# Nano-vLLM-Triton

[English](README.md) | [ä¸­æ–‡](README_zh.md)

åŸºäº [Nano-vLLM](https://github.com/GeeeekExplorer/nano-vllm) å’Œ [OpenAI Triton](https://github.com/openai/triton) æ„å»ºçš„è½»é‡çº§ã€ä¼˜åŒ–ç‰ˆ vLLM å®ç°ã€‚

## ğŸ†• æ›´æ–°å†…å®¹

æœ¬é¡¹ç›®åœ¨åŸå§‹ Nano-vLLM åŸºç¡€ä¸Šè¿›è¡Œäº†ä»¥ä¸‹æ”¹è¿›ï¼š

1. **æ‰©å±•æ¨¡å‹æ”¯æŒ**ï¼šæ–°å¢å…¨é¢æ”¯æŒï¼š
   - Qwen2 ç³»åˆ—æ¨¡å‹
   - Qwen2.5 ç³»åˆ—æ¨¡å‹
   - Qwen3-MoE ç³»åˆ—æ¨¡å‹
   - Llama ç³»åˆ—æ¨¡å‹
   - åŸæœ‰çš„ Qwen3 ç³»åˆ—æ¨¡å‹

2. **Triton ä¼˜åŒ–**ï¼šå®ç°è‡ªå®šä¹‰ Triton ç®—å­ï¼š
   - `softmax_online`ï¼šæ›¿æ¢ `torch.softmax`
   - `cat_cos_sin`ï¼šæ›¿æ¢ `torch.cat(cos, sin, dim=-1)`
   - **æ€§èƒ½æå‡**ï¼šå¹³å‡é€Ÿåº¦æå‡ 101.93 token/s

## ğŸ“¦ å®‰è£…

```bash
git clone https://github.com/cosmoliu2002/nano-vllm-triton.git
cd nano-vllm-triton
pip install -e .
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. Python

**example.py**
```bash
python example.py --model-path /path/to/your/model
```

**æ”¯æŒå‚æ•°**
```bash
--model-path
--tensor-parallel-size
--enforce-eager
--temperature
--max-tokens
```

### 2. Shell

**run_example.sh**

```bash
bash run_example.sh
```
**æ”¯æŒå‚æ•°**
**`config_example.yaml`**
```yaml
model_path: "/path/to/your/model"
tensor_parallel_size: 1
enforce_eager: true
temperature: 0.6
max_tokens: 256
```

## ğŸ“Š æ€§èƒ½æµ‹è¯•

**run_bench.sh**

```bash
bash run_bench.sh
```
**æ”¯æŒå‚æ•°**
**`config_bench.yaml`**
```yaml
model_path: "/path/to/your/model"
engine: "nanovllmtriton"             # nanovllmtriton æˆ– vllm
```

**æµ‹è¯•é…ç½®ï¼š**
- ç¡¬ä»¶ï¼šNVIDIA A10ï¼ˆç”±ModelScope Notebookæä¾›æ”¯æŒï¼‰
- æ¨¡å‹ï¼šå¤šç§ Qwen å’Œ Llama æ¨¡å‹
- æ€»è¯·æ±‚æ•°ï¼š256 ä¸ªåºåˆ—
- è¾“å…¥é•¿åº¦ï¼š100-1024 tokens éšæœºé‡‡æ ·
- è¾“å‡ºé•¿åº¦ï¼š100-1024 tokens éšæœºé‡‡æ ·
- æµ‹è¯•æ¬¡æ•°ï¼šæ¯ä¸ªæ¨¡å‹æµ‹è¯•5æ¬¡å–å¹³å‡å€¼

**æµ‹è¯•ç»“æœï¼š**

| æ¨¡å‹ | vLLM ååé‡ (tokens/s) | Nano vLLM Triton ååé‡ (tokens/s) | Nano vLLM ååé‡ (tokens/s) | æ€§èƒ½æå‡(vs Nano vLLM) |
|-------|---------------------------|----------------------------------------|----------------------------------|----------------------------------|
| Llama3.2-1B | 5455.85 | 5432.24 | 5394.15 | +38.09 |
| Qwen2-0.5B | 9501.11 | 10198.84 | 10030.08 | +168.76 |
| Qwen2.5-0.5B | 9441.46 | 10221.94 | 10033.20 | +188.74 |
| Qwen3-0.6B | 3465.40 | 2970.81 | 2958.67 | +12.14 |

## ğŸ› ï¸ æ”¯æŒçš„æ¨¡å‹

- **Qwen ç³»åˆ—**ï¼šQwen2ã€Qwen2.5ã€Qwen3ã€Qwen3-MoE
- **Llama ç³»åˆ—**ï¼šLlama 2ã€Llama 3ã€Llama 3.1ã€Llama 3.2

## ğŸ—ºï¸ æœªæ¥è§„åˆ’

é€šè¿‡é€æ­¥ä½¿ç”¨è‡ªå®šä¹‰ Triton å†…æ ¸æ›¿æ¢æ‰€æœ‰ PyTorch å®ç°

## ğŸ™ è‡´è°¢

- [Nano-vLLM](https://github.com/GeeeekExplorer/nano-vllm)
- Qwen2ã€Qwen2.5ã€Qwen3-MoEã€Llama ç³»åˆ—æ¨¡å‹æ”¯æŒ [Nano-vLLM-gogongxt](https://github.com/gogongxt/nano-vllm)
- [OpenAI Triton](https://github.com/openai/triton)